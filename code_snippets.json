{
  "snippets": [
    {
      "term": "ReLU",
      "cat": "活性化関数",
      "code": "import tensorflow as tf\n\n# Denseレイヤーで指定\nmodel.add(tf.keras.layers.Dense(\n    64,\n    # x>0→x, x≤0→0\n    activation='relu'\n))\n\n# 関数として使用\nx = tf.keras.activations.relu(x)",
      "note": "x<0で勾配0。深層学習の標準活性化関数",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/relu"
    },
    {
      "term": "Leaky ReLU",
      "cat": "活性化関数",
      "code": "from tensorflow.keras.layers \\\n    import LeakyReLU\n\nmodel.add(LeakyReLU(\n    alpha=0.01  # 負の傾き係数\n))\n\n# alpha=0.1 → 負側の勾配を大きめに\nx = LeakyReLU(alpha=0.1)(x)",
      "note": "x<0でも小さな勾配αを持ち、dying neuron問題を緩和",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/LeakyReLU"
    },
    {
      "term": "GELU",
      "cat": "活性化関数",
      "code": "import tensorflow as tf\n\nmodel.add(tf.keras.layers.Dense(\n    64,\n    # ガウス誤差線形ユニット\n    activation='gelu'\n))\n\n# 関数として直接適用\nx = tf.keras.activations.gelu(x)",
      "note": "Transformerで標準的に使用される活性化関数",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/gelu"
    },
    {
      "term": "Sigmoid function",
      "cat": "活性化関数",
      "code": "import tensorflow as tf\n\nmodel.add(tf.keras.layers.Dense(\n    1,  # 二値分類は出力1\n    # 出力を(0,1)に変換\n    activation='sigmoid'\n))\n\n# 関数として使用\nx = tf.keras.activations.sigmoid(x)",
      "note": "出力を(0,1)に写像。二値分類の出力層で使用",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/sigmoid"
    },
    {
      "term": "tanh",
      "cat": "活性化関数",
      "code": "import tensorflow as tf\n\nmodel.add(tf.keras.layers.Dense(\n    64,\n    # (-1,1)に写像\n    activation='tanh'\n))\nx = tf.keras.activations.tanh(x)",
      "note": "出力を(-1,1)に写像。RNNの隠れ状態で使用",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/tanh"
    },
    {
      "term": "ソフトマックス関数",
      "cat": "活性化関数",
      "code": "import tensorflow as tf\n\n# 多クラス分類の出力層\nmodel.add(tf.keras.layers.Dense(\n    10,  # クラス数\n    # 確率分布に変換(合計1.0)\n    activation='softmax'\n))\n\n# 温度付きSoftmax\ndef softmax_with_temp(logits, temp=1.0):\n    # temp:大→平坦, 小→尖鋭\n    return tf.nn.softmax(logits / temp)",
      "note": "K次元ベクトルを確率分布に変換。多クラス分類の出力層",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/softmax"
    },
    {
      "term": "Swish",
      "cat": "活性化関数",
      "code": "import tensorflow as tf\n\nmodel.add(tf.keras.layers.Dense(\n    64,\n    # x * sigmoid(x)\n    activation='swish'\n))\n# EfficientNet等で採用",
      "note": "自己ゲート型活性化関数。EfficientNetで採用",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/swish"
    },
    {
      "term": "Adam",
      "cat": "最適化",
      "code": "import tensorflow as tf\n\nopt = tf.keras.optimizers.Adam(\n    learning_rate=0.001,\n    beta_1=0.9,    # 勾配の移動平均\n    beta_2=0.999,  # 勾配²の移動平均\n    epsilon=1e-07\n)\nmodel.compile(optimizer=opt, loss='mse')",
      "note": "Momentum+RMSPropの統合。最も広く使われる最適化器",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam"
    },
    {
      "term": "AdamW",
      "cat": "最適化",
      "code": "import tensorflow as tf\n\nopt = tf.keras.optimizers.AdamW(\n    learning_rate=0.001,\n    # L2と独立した重み減衰\n    weight_decay=0.01\n)\nmodel.compile(optimizer=opt, loss='mse')",
      "note": "重み減衰をL2正則化から分離した改良版Adam",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/AdamW"
    },
    {
      "term": "確率的勾配降下法",
      "cat": "最適化",
      "code": "import tensorflow as tf\n\nopt = tf.keras.optimizers.SGD(\n    learning_rate=0.01,\n    momentum=0.9, # 慣性項\n    nesterov=True # NAG\n)\n# Categorical Crossentropy\nmodel.compile(\n    optimizer=opt,\n    loss='categorical_crossentropy'\n)",
      "note": "基本の勾配降下法。momentum/nesterovオプション付き",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD"
    },
    {
      "term": "学習率スケジューリング",
      "cat": "最適化",
      "code": "import tensorflow as tf\n\n# コサインアニーリング\nsched = tf.keras.optimizers.schedules \\\n    .CosineDecay(\n        initial_learning_rate=0.01,\n        decay_steps=1000\n    )\nopt = tf.keras.optimizers.Adam(\n    learning_rate=sched\n)\n\n# ReduceLROnPlateau\nreduce_lr = tf.keras.callbacks \\\n    .ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.5, # 半分に\n        patience=5\n    )",
      "note": "訓練中に学習率を動的に変更する手法",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules"
    },
    {
      "term": "RMSProp",
      "cat": "最適化",
      "code": "import tensorflow as tf\n\noptimizer = tf.keras.optimizers.RMSprop(\n    learning_rate=0.001, # 学習率\n    rho=0.9              # 勾配²の移動平均の減衰率（大きい→安定、小さい→追従が速い）\n)\nmodel.compile(optimizer=optimizer, loss='mse')",
      "note": "勾配の二乗の移動平均で学習率を適応的に調整",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop"
    },
    {
      "term": "交差エントロピー",
      "cat": "損失関数",
      "code": "import tensorflow as tf\n\n# 二値分類 (出力:sigmoid)\nmodel.compile(\n    loss='binary_crossentropy'\n)\n\n# 多クラス (one-hot)\nmodel.compile(\n    loss='categorical_crossentropy'\n)\n\n# 多クラス (整数ラベル)\n# one-hot変換不要でメモリ節約\nmodel.compile(\n    loss='sparse_categorical_crossentropy'\n)",
      "note": "分類タスクの標準損失関数",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy"
    },
    {
      "term": "損失関数",
      "cat": "損失関数",
      "code": "import tensorflow as tf\n\n# MSE: 二乗誤差 (回帰)\nloss = tf.keras.losses \\\n    .MeanSquaredError()\n\n# MAE: 絶対誤差 (外れ値に強い)\nloss = tf.keras.losses \\\n    .MeanAbsoluteError()\n\n# Huber: MSEとMAEのハイブリッド\nloss = tf.keras.losses.Huber(\n    delta=1.0\n)\n\n# カスタム損失関数\n@tf.function\ndef custom_loss(y_true, y_pred):\n    return tf.reduce_mean(\n        tf.square(y_true - y_pred)\n    )",
      "note": "モデル予測と正解の乖離を定量化",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/losses"
    },
    {
      "term": "Dropout",
      "cat": "正則化",
      "code": "import tensorflow as tf\n\n# Sequential\nmodel.add(tf.keras.layers.Dropout(\n    0.5  # 50%をゼロ化\n))\n\n# Functional (訓練時のみ)\nx = tf.keras.layers.Dropout(0.3)(\n    x, training=True\n)\n\n# SpatialDropout (CNN向け)\nmodel.add(\n    tf.keras.layers.SpatialDropout2D(\n        0.2  # チャネルごとドロップ\n    )\n)",
      "note": "訓練時にランダムにユニットを無効化し過学習を防止",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout"
    },
    {
      "term": "バッチ正規化",
      "cat": "正則化",
      "code": "import tensorflow as tf\n\n# Conv -> BN -> ReLU\nx = tf.keras.layers.Conv2D(\n    64, 3,\n    use_bias=False # BNにバイアス有\n)(x)\n# ミニバッチ内正規化\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.ReLU()(x)",
      "note": "ミニバッチ内で正規化し学習を安定化",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization"
    },
    {
      "term": "レイヤー正規化",
      "cat": "正則化",
      "code": "import tensorflow as tf\n\n# バッチサイズ非依存 (Transformer等)\nx = tf.keras.layers \\\n    .LayerNormalization(\n        epsilon=1e-6\n    )(x)",
      "note": "各サンプルの特徴量次元で正規化。バッチサイズに非依存",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization"
    },
    {
      "term": "L1正則化",
      "cat": "正則化",
      "code": "import tensorflow as tf\n\n# L1正則化 (スパース化)\nmodel.add(tf.keras.layers.Dense(\n    64,\n    kernel_regularizer=\\\n        tf.keras.regularizers.L1(0.01)\n))\n\n# Elastic Net (L1+L2)\nmodel.add(tf.keras.layers.Dense(\n    64,\n    kernel_regularizer=\\\n        tf.keras.regularizers.L1L2(\n            l1=0.01, l2=0.01\n        )\n))",
      "note": "パラメータを疎にし特徴選択効果がある",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/L1"
    },
    {
      "term": "L2正則化",
      "cat": "正則化",
      "code": "import tensorflow as tf\n\n# L2正則化 (重み抑制)\nmodel.add(tf.keras.layers.Dense(\n    64,\n    kernel_regularizer=\\\n        tf.keras.regularizers.L2(0.01)\n))",
      "note": "パラメータを小さく保ち過学習を抑制",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/L2"
    },
    {
      "term": "早期終了",
      "cat": "正則化",
      "code": "import tensorflow as tf\n\nstop = tf.keras.callbacks \\\n    .EarlyStopping(\n        monitor='val_loss',\n        patience=10,\n        restore_best_weights=True\n    )\nmodel.fit(x, y, callbacks=[stop])",
      "note": "検証損失が改善しなくなったら訓練を停止",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping"
    },
    {
      "term": "畳み込み",
      "cat": "レイヤー",
      "code": "import tensorflow as tf\n\n# 2D畳み込み (画像)\nmodel.add(tf.keras.layers.Conv2D(\n    filters=32, kernel_size=(3,3),\n    strides=1, padding='same',\n    activation='relu'\n))\n\n# 1D畳み込み (系列)\nmodel.add(tf.keras.layers.Conv1D(\n    64, 3, activation='relu'\n))\n\n# 転置畳み込み (アップサンプリング)\nmodel.add(\n    tf.keras.layers.Conv2DTranspose(\n        32, 3, strides=2\n    )\n)",
      "note": "局所的な特徴を抽出するフィルタ演算",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D"
    },
    {
      "term": "プーリング",
      "cat": "レイヤー",
      "code": "import tensorflow as tf\n\n# MaxPool (特徴維持)\nmodel.add(\n    tf.keras.layers.MaxPooling2D(\n        pool_size=(2,2)\n    )\n)\n\n# AvgPool (平滑化)\nmodel.add(\n    tf.keras.layers.AveragePooling2D(\n        pool_size=(2,2)\n    )\n)\n\n# GlobalAvg (分類ヘッド前)\nmodel.add(\n    tf.keras.layers \\\n        .GlobalAveragePooling2D()\n)",
      "note": "空間解像度を縮小し位置不変性を獲得",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPooling2D"
    },
    {
      "term": "LSTM",
      "cat": "レイヤー",
      "code": "import tensorflow as tf\n\n# Stack LSTM\nmodel.add(tf.keras.layers.LSTM(\n    128, return_sequences=True\n))\nmodel.add(tf.keras.layers.LSTM(64))\n\n# Bidirectional\nmodel.add(\n    tf.keras.layers.Bidirectional(\n        tf.keras.layers.LSTM(64)\n    )\n)",
      "note": "長期依存性を学習できるゲート付きRNN",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM"
    },
    {
      "term": "GRU",
      "cat": "レイヤー",
      "code": "import tensorflow as tf\n\nmodel.add(tf.keras.layers.GRU(\n    128,\n    return_sequences=True,\n    dropout=0.2,\n    recurrent_dropout=0.1\n))",
      "note": "LSTMの簡略版。パラメータが少なく高速",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU"
    },
    {
      "term": "Embedding",
      "cat": "レイヤー",
      "code": "import tensorflow as tf\n\n# Embedding\nmodel.add(tf.keras.layers.Embedding(\n    input_dim=10000, # 語彙数\n    output_dim=128,  # 次元数\n    input_length=100\n))",
      "note": "離散トークンを連続ベクトルに変換",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding"
    },
    {
      "term": "Attention",
      "cat": "レイヤー",
      "code": "import tensorflow as tf\n\n# Keras組み込み (Bahdanau)\nattention = tf.keras.layers \\\n    .Attention()\noutput = attention([query, value])\n\n# MultiHeadAttention\nmha = tf.keras.layers \\\n    .MultiHeadAttention(\n        num_heads=8,\n        key_dim=64\n    )\n# query:先, value:値, key:鍵\noutput = mha(query, value, key)",
      "note": "入力の重要部分に動的に注目する機構",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention"
    },
    {
      "term": "Dense",
      "cat": "レイヤー",
      "code": "import tensorflow as tf\n\nmodel.add(tf.keras.layers.Dense(\n    units=128, # 出力数\n    activation='relu',\n    kernel_initializer='he_normal',\n    # L2正則化\n    kernel_regularizer=\\\n        tf.keras.regularizers.L2(0.01)\n))",
      "note": "全結合層。input×weightsの行列演算",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense"
    },
    {
      "term": "Flatten",
      "cat": "レイヤー",
      "code": "import tensorflow as tf\n\n# CNN→Dense接続時\nmodel.add(tf.keras.layers.Conv2D(64, 3))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(10))",
      "note": "多次元テンソルを1Dに展開",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten"
    },
    {
      "term": "残差接続",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\n\n# Residual Block\ndef residual_block(x, filters):\n    shortcut = x\n    x = tf.keras.layers.Conv2D(filters, 3, padding='same')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Conv2D(filters, 3, padding='same')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Add()([shortcut, x])\n    x = tf.keras.layers.ReLU()(x)\n    return x",
      "note": "入力をスキップ接続で加算し勾配消失を防止",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Add"
    },
    {
      "term": "ResNet",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\n\n# 学習済みResNet50\nbase = tf.keras.applications \\\n    .ResNet50(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(224,224,3)\n)\n\n# ファインチューニング\nbase.trainable = False\nmodel = tf.keras.Sequential([\n    base,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(\n        10, activation='softmax'\n    )\n])",
      "note": "残差接続を用いた深層CNN",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50"
    },
    {
      "term": "VGG",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\n\nbase = tf.keras.applications \\\n    .VGG16(\n        weights='imagenet',\n        include_top=False,\n        input_shape=(224,224,3)\n    )\n# シンプルで高精度だが重い\nmodel = tf.keras.Sequential([\n    base,\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')\n])",
      "note": "3x3畳み込みを積み重ねたシンプルなCNN",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16"
    },
    {
      "term": "EfficientNet",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\n\nbase = tf.keras.applications.EfficientNetV2B0(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(224,224,3)\n)\nmodel = tf.keras.Sequential([\n    base,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(10, activation='softmax')\n])",
      "note": "深さ・幅・解像度を複合スケーリング",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetV2B0"
    },
    {
      "term": "U-Net",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\nfrom tensorflow.keras import layers\n\ndef unet(input_shape=(256,256,1)):\n    inputs = layers.Input(input_shape)\n    # Encoder\n    c1 = layers.Conv2D(64,3,padding='same',activation='relu')(inputs)\n    p1 = layers.MaxPooling2D()(c1)\n    c2 = layers.Conv2D(128,3,padding='same',activation='relu')(p1)\n    p2 = layers.MaxPooling2D()(c2)\n    # Bottleneck\n    b = layers.Conv2D(256,3,padding='same',activation='relu')(p2)\n    # Decoder\n    u1 = layers.Conv2DTranspose(128,2,strides=2)(b)\n    u1 = layers.Concatenate()([u1, c2])\n    u1 = layers.Conv2D(128,3,padding='same',activation='relu')(u1)\n    u2 = layers.Conv2DTranspose(64,2,strides=2)(u1)\n    u2 = layers.Concatenate()([u2, c1])\n    u2 = layers.Conv2D(64,3,padding='same',activation='relu')(u2)\n    out = layers.Conv2D(1,1,activation='sigmoid')(u2)\n    return tf.keras.Model(inputs, out)",
      "note": "Encoder-Decoder+スキップ接続のセグメンテーションモデル",
      "doc": "https://www.tensorflow.org/tutorials/images/segmentation"
    },
    {
      "term": "Transformer",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\nfrom tensorflow.keras import layers\n\ndef transformer_block(embed_dim, num_heads, ff_dim, rate=0.1):\n    inputs = layers.Input(shape=(None, embed_dim))\n    attn = layers.MultiHeadAttention(\n        num_heads=num_heads, key_dim=embed_dim\n    )(inputs, inputs)\n    attn = layers.Dropout(rate)(attn)\n    out1 = layers.LayerNormalization()(inputs + attn)\n    ff = layers.Dense(ff_dim, activation='gelu')(out1)\n    ff = layers.Dense(embed_dim)(ff)\n    ff = layers.Dropout(rate)(ff)\n    out2 = layers.LayerNormalization()(out1 + ff)\n    return tf.keras.Model(inputs, out2)",
      "note": "Self-Attentionベースのアーキテクチャ",
      "doc": "https://www.tensorflow.org/text/tutorials/transformer"
    },
    {
      "term": "GAN",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\n\n# Generator\ndef make_generator():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Dense(256, activation='relu', input_shape=(100,)),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dense(512, activation='relu'),\n        tf.keras.layers.Dense(784, activation='sigmoid'),\n        tf.keras.layers.Reshape((28,28,1))\n    ])\n    return model\n\n# Discriminator\ndef make_discriminator():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Flatten(input_shape=(28,28,1)),\n        tf.keras.layers.Dense(512, activation='relu'),\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ])\n    return model",
      "note": "生成器と判別器の敵対的学習",
      "doc": "https://www.tensorflow.org/tutorials/generative/dcgan"
    },
    {
      "term": "VAE",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\nfrom tensorflow.keras import layers\n\n# Encoder\nlatent_dim = 2\nencoder_inputs = layers.Input(shape=(28,28,1))\nx = layers.Flatten()(encoder_inputs)\nx = layers.Dense(256, activation='relu')(x)\nz_mean = layers.Dense(latent_dim)(x)\nz_log_var = layers.Dense(latent_dim)(x)\n\n# Reparameterization trick\ndef sampling(args):\n    z_mean, z_log_var = args\n    eps = tf.random.normal(shape=tf.shape(z_mean))\n    return z_mean + tf.exp(0.5*z_log_var) * eps",
      "note": "確率的潜在空間を持つ生成モデル",
      "doc": "https://www.tensorflow.org/tutorials/generative/cvae"
    },
    {
      "term": "オートエンコーダ",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\n\n# Encoder\nencoder = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(32, activation='relu')  # bottleneck\n])\n# Decoder\ndecoder = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(784, activation='sigmoid')\n])\n# Autoencoder\ninputs = tf.keras.Input(shape=(784,))\nencoded = encoder(inputs)\ndecoded = decoder(encoded)\nautoencoder = tf.keras.Model(inputs, decoded)\nautoencoder.compile(optimizer='adam', loss='mse')",
      "note": "入力を圧縮・復元する教師なし学習モデル",
      "doc": "https://www.tensorflow.org/tutorials/generative/autoencoder"
    },
    {
      "term": "データ拡張",
      "cat": "前処理",
      "code": "import tensorflow as tf\n\naug = tf.keras.Sequential([\n    # ランダム反転\n    tf.keras.layers.RandomFlip('horizontal'),\n    # 回転 ±10%\n    tf.keras.layers.RandomRotation(0.1),\n    # ズーム ±10%\n    tf.keras.layers.RandomZoom(0.1),\n])\n\nmodel = tf.keras.Sequential([\n    aug,\n    tf.keras.layers.Conv2D(32, 3)\n])",
      "note": "訓練データを変換して量を増やし汎化性能を向上",
      "doc": "https://www.tensorflow.org/tutorials/images/data_augmentation"
    },
    {
      "term": "RandAugment",
      "cat": "前処理",
      "code": "import tensorflow as tf\n\n# tf.image ベースの実装\ndef randaugment(image, num_ops=2, magnitude=9):\n    augmentations = [\n        lambda img: tf.image.random_brightness(img, 0.2),\n        lambda img: tf.image.random_contrast(img, 0.8, 1.2),\n        lambda img: tf.image.random_saturation(img, 0.8, 1.2),\n        lambda img: tf.image.rot90(img, k=tf.random.uniform([], 0, 4, tf.int32)),\n    ]\n    for _ in range(num_ops):\n        op = augmentations[tf.random.uniform([], 0, len(augmentations), tf.int32)]\n        image = op(image)\n    return image",
      "note": "ランダムにN個の拡張を適用するシンプルな手法",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/image"
    },
    {
      "term": "Mixup",
      "cat": "前処理",
      "code": "import tensorflow as tf\n\ndef mixup(images, labels, alpha=0.2):\n    batch_size = tf.shape(images)[0]\n    lam = tf.random.uniform([batch_size,1,1,1], 0, alpha)\n    indices = tf.random.shuffle(tf.range(batch_size))\n    mixed_images = lam*images + (1-lam)*tf.gather(images, indices)\n    lam_labels = tf.reshape(lam, [batch_size,1])\n    mixed_labels = lam_labels*labels + (1-lam_labels)*tf.gather(labels, indices)\n    return mixed_images, mixed_labels",
      "note": "2つのサンプルを線形補間して正則化効果を得る"
    },
    {
      "term": "転移学習",
      "cat": "学習手法",
      "code": "import tensorflow as tf\n\nbase = tf.keras.applications \\\n    .MobileNetV2(\n        weights='imagenet',\n        include_top=False\n    )\nbase.trainable = False\n\nmodel = tf.keras.Sequential([\n    base,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(5)\n])\n\n# 段階的解凍\nbase.trainable = True\nfor layer in base.layers[:-30]:\n    layer.trainable = False",
      "note": "事前学習モデルを新タスクに適応させる手法",
      "doc": "https://www.tensorflow.org/tutorials/images/transfer_learning"
    },
    {
      "term": "ファインチューニング",
      "cat": "学習手法",
      "code": "import tensorflow as tf\n\n# 低学習率で微調整\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(\n        learning_rate=1e-5\n    ),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# 上位層のみ学習可\nfor layer in model.layers[-10:]:\n    layer.trainable = True",
      "note": "事前学習済みモデルの一部をタスク固有データで再学習",
      "doc": "https://www.tensorflow.org/tutorials/images/transfer_learning"
    },
    {
      "term": "知識蒸留",
      "cat": "学習手法",
      "code": "import tensorflow as tf\n\ndef dist_loss(y_true, y_pred,\n              teacher, temp=3, alpha=0.5):\n    # Soft targets\n    soft_t = tf.nn.softmax(teacher / temp)\n    soft_p = tf.nn.softmax(y_pred / temp)\n    \n    # KL Divergence\n    distill = tf.keras.losses \\\n        .KLDivergence()(soft_t, soft_p)\n    \n    # Hard loss\n    hard = tf.keras.losses \\\n        .SparseCategoricalCrossentropy(\n            from_logits=True)(y_true, y_pred)\n            \n    return alpha * distill * temp**2 \\\n           + (1-alpha) * hard",
      "note": "大きな教師モデルの知識を小さな生徒モデルに転移",
      "doc": "https://www.tensorflow.org/model_optimization/guide/knowledge_distillation"
    },
    {
      "term": "勾配クリッピング",
      "cat": "学習手法",
      "code": "import tensorflow as tf\n\n# 勾配クリッピング(norm)\nopt = tf.keras.optimizers.Adam(\n    learning_rate=0.001,\n    clipnorm=1.0\n)",
      "note": "勾配爆発を防止するためにノルムを制限",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam"
    },
    {
      "term": "バッチサイズ",
      "cat": "学習手法",
      "code": "import tensorflow as tf\n\nmodel.fit(\n    x_train, y_train,\n    batch_size=32,\n    epochs=100,\n    validation_split=0.2\n)\n\n# tf.data (推奨)\nds = tf.data.Dataset \\\n    .from_tensor_slices((x, y))\nds = ds.shuffle(1000)\nds = ds.batch(64)\nds = ds.prefetch(tf.data.AUTOTUNE)",
      "note": "1回の更新で使用するサンプル数",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"
    },
    {
      "term": "Depthwise Separable Conv",
      "cat": "レイヤー",
      "code": "import tensorflow as tf\n\n# Depthwise Separable Convolution\nmodel.add(tf.keras.layers.SeparableConv2D(\n    filters=64, kernel_size=3,\n    padding='same', activation='relu'\n))\n\n# MobileNetで多用される",
      "note": "チャネル毎の空間畳み込み+1x1畳み込みで軽量化",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/SeparableConv2D"
    },
    {
      "term": "MobileNet",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\n\nbase = tf.keras.applications \\\n    .MobileNetV2(\n        weights='imagenet',\n        include_top=False,\n        input_shape=(224,224,3),\n        alpha=1.0  # モデル幅\n    )\n# 軽量・高速 (スマホ向け)\n\n# TFLite向け量子化\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\ntflite_model = converter.convert()",
      "note": "Depthwise Separable Convによる軽量モデル",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV2"
    },
    {
      "term": "重み初期化",
      "cat": "学習手法",
      "code": "import tensorflow as tf\n\n# He (ReLU系)\nmodel.add(tf.keras.layers.Dense(\n    64, activation='relu',\n    kernel_initializer='he_normal'\n))\n\n# Xavier/Glorot (tanh系)\nmodel.add(tf.keras.layers.Dense(\n    64, activation='tanh',\n    kernel_initializer='glorot_uniform'\n))",
      "note": "層の重みの初期値を適切に設定し学習を安定化",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/initializers"
    },
    {
      "term": "PCA",
      "cat": "次元削減",
      "code": "import tensorflow as tf\nimport numpy as np\n\n# TensorFlowでPCA\ndef pca_tf(data, n_components):\n    mean = tf.reduce_mean(data, axis=0)\n    centered = data - mean\n    cov = tf.linalg.matmul(centered, centered, transpose_a=True) / tf.cast(tf.shape(data)[0]-1, tf.float32)\n    eigenvalues, eigenvectors = tf.linalg.eigh(cov)\n    # 上位n_components\n    idx = tf.argsort(eigenvalues, direction='DESCENDING')[:n_components]\n    components = tf.gather(eigenvectors, idx, axis=1)\n    return tf.linalg.matmul(centered, components)",
      "note": "分散最大方向に次元削減する主成分分析",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/linalg/eigh"
    },
    {
      "term": "混同行列",
      "cat": "評価",
      "code": "import tensorflow as tf\n\n# 予測と正解から混同行列\ny_true = [0, 1, 2, 0, 1, 2]\ny_pred = [0, 2, 1, 0, 1, 1]\n\ncm = tf.math.confusion_matrix(y_true, y_pred, num_classes=3)\nprint(cm)\n\n# Kerasメトリクス\nmetric = tf.keras.metrics.AUC()\nmetric.update_state(y_true_binary, y_pred_proba)",
      "note": "分類結果をTP/FP/TN/FNで整理した行列",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/math/confusion_matrix"
    },
    {
      "term": "F1スコア",
      "cat": "評価",
      "code": "import tensorflow as tf\n\nclass F1Score(tf.keras.metrics.Metric):\n    def __init__(self, name='f1', **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.precision = tf.keras.metrics.Precision()\n        self.recall = tf.keras.metrics.Recall()\n    def update_state(self, y_true, y_pred, **kw):\n        self.precision.update_state(y_true, y_pred, **kw)\n        self.recall.update_state(y_true, y_pred, **kw)\n    def result(self):\n        p = self.precision.result()\n        r = self.recall.result()\n        return 2 * p * r / (p + r + 1e-7)\n\nmodel.compile(metrics=[F1Score()])",
      "note": "精度と再現率の調和平均",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics"
    },
    {
      "term": "モデルの保存",
      "cat": "運用",
      "code": "import tensorflow as tf\n\n# SavedModel (全保存)\nmodel.save('my_model')\nloaded = tf.keras.models \\\n    .load_model('my_model')\n\n# 重みのみ\nmodel.save_weights('w.h5')\nmodel.load_weights('w.h5')\n\n# Checkpoint\ncp = tf.keras.callbacks \\\n    .ModelCheckpoint(\n        'best.keras',\n        save_best_only=True\n    )",
      "note": "学習済みモデルの永続化と復元",
      "doc": "https://www.tensorflow.org/guide/keras/save_and_serialize"
    },
    {
      "term": "TensorBoard",
      "cat": "運用",
      "code": "import tensorflow as tf\n\n# TensorBoard\ntb = tf.keras.callbacks \\\n    .TensorBoard(\n        log_dir='./logs',\n        histogram_freq=1\n    )\n\n# Custom Scalar\nwriter = tf.summary \\\n    .create_file_writer('./logs')\nwith writer.as_default():\n    tf.summary.scalar(\n        'custom', value, step=epoch\n    )",
      "note": "学習過程の可視化ツール",
      "doc": "https://www.tensorflow.org/tensorboard"
    },
    {
      "term": "GPU / CUDA",
      "cat": "運用",
      "code": "import tensorflow as tf\n\n# GPU確認\nprint(tf.config.list_physical_devices('GPU'))\n\n# メモリ成長 (OOM防止)\ngpus = tf.config.list_physical_devices('GPU')\nfor gpu in gpus:\n    tf.config.experimental \\\n        .set_memory_growth(gpu, True)\n\n# 特定GPU指定\nwith tf.device('/GPU:0'):\n    model = build_model()",
      "note": "GPUを使用した高速計算",
      "doc": "https://www.tensorflow.org/guide/gpu"
    },
    {
      "term": "混合精度",
      "cat": "運用",
      "code": "import tensorflow as tf\n\n# 混合精度 (float16)\ntf.keras.mixed_precision \\\n    .set_global_policy('mixed_float16')\n\n# 出力層はfloat32推奨\nmodel.add(tf.keras.layers.Dense(\n    10, dtype='float32'\n))",
      "note": "float16とfloat32を混合し高速化とメモリ節約",
      "doc": "https://www.tensorflow.org/guide/mixed_precision"
    },
    {
      "term": "量子化",
      "cat": "運用",
      "code": "import tensorflow as tf\n\n# Post-training Quantization\nconverter = tf.lite.TFLiteConverter \\\n    .from_keras_model(model)\n\n# デフォルト最適化\nconverter.optimizations = [\n    tf.lite.Optimize.DEFAULT\n]\ntflite_model = converter.convert()",
      "note": "モデルを低ビット化し推論を高速化・軽量化",
      "doc": "https://www.tensorflow.org/lite/performance/post_training_quantization"
    },
    {
      "term": "tf.data",
      "cat": "運用",
      "code": "import tensorflow as tf\n\n# tf.data Pipeline\nds = tf.data.Dataset \\\n    .from_tensor_slices((x, y))\n\nds = ds.shuffle(1000) \\\n       .map(preprocess, \n            num_parallel_calls=tf.data.AUTOTUNE) \\\n       .batch(32) \\\n       .prefetch(tf.data.AUTOTUNE)",
      "note": "高効率なデータ入力パイプライン",
      "doc": "https://www.tensorflow.org/guide/data"
    },
    {
      "term": "物体検出",
      "cat": "応用",
      "code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\n# TF Hub から学習済みモデル\ndetector = hub.load(\n    'https://tfhub.dev/tensorflow/efficientdet/lite0/detection/1'\n)\n\n# 推論\nresult = detector(image_tensor)\nboxes = result['detection_boxes']\nscores = result['detection_scores']\nclasses = result['detection_classes']",
      "note": "画像内のオブジェクトを検出しバウンディングボックスを出力",
      "doc": "https://www.tensorflow.org/hub/tutorials/object_detection"
    },
    {
      "term": "セマンティックセグメンテーション",
      "cat": "応用",
      "code": "import tensorflow as tf\n\n# DeepLabV3+風\nbase = tf.keras.applications.MobileNetV2(\n    input_shape=(256,256,3), include_top=False\n)\n\n# Decoderでアップサンプリング\nx = base.output\nx = tf.keras.layers.Conv2DTranspose(256, 3, strides=2, padding='same')(x)\nx = tf.keras.layers.Conv2DTranspose(128, 3, strides=2, padding='same')(x)\noutput = tf.keras.layers.Conv2D(21, 1, activation='softmax')(x)\n\nmodel = tf.keras.Model(base.input, output)\nmodel.compile(loss='sparse_categorical_crossentropy')",
      "note": "ピクセル単位でクラスを分類",
      "doc": "https://www.tensorflow.org/tutorials/images/segmentation"
    },
    {
      "term": "Seq2Seq",
      "cat": "応用",
      "code": "import tensorflow as tf\n\n# Encoder\nencoder_inputs = tf.keras.Input(shape=(None,))\nenc_emb = tf.keras.layers.Embedding(src_vocab, 256)(encoder_inputs)\nenc_out, state_h, state_c = tf.keras.layers.LSTM(256, return_state=True)(enc_emb)\n\n# Decoder\ndecoder_inputs = tf.keras.Input(shape=(None,))\ndec_emb = tf.keras.layers.Embedding(tgt_vocab, 256)(decoder_inputs)\ndec_out = tf.keras.layers.LSTM(256, return_sequences=True)(\n    dec_emb, initial_state=[state_h, state_c]\n)\noutput = tf.keras.layers.Dense(tgt_vocab, activation='softmax')(dec_out)",
      "note": "入力系列→出力系列の変換モデル",
      "doc": "https://www.tensorflow.org/text/tutorials/nmt_with_attention"
    },
    {
      "term": "Word2Vec",
      "cat": "応用",
      "code": "import tensorflow as tf\n\n# Skip-gram Word2Vec\nvocab_size = 10000\nembedding_dim = 128\n\ntarget = tf.keras.Input(shape=(1,))\ncontext = tf.keras.Input(shape=(1,))\n\nembedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\ntarget_emb = embedding(target)\ncontext_emb = embedding(context)\n\ndot = tf.keras.layers.Dot(axes=-1)([target_emb, context_emb])\noutput = tf.keras.layers.Flatten()(dot)\noutput = tf.keras.layers.Dense(1, activation='sigmoid')(output)\n\nmodel = tf.keras.Model([target, context], output)",
      "note": "単語をベクトル空間に埋め込むモデル",
      "doc": "https://www.tensorflow.org/tutorials/text/word2vec"
    },
    {
      "term": "勾配テープ",
      "cat": "基礎",
      "code": "import tensorflow as tf\n\n# 自動微分\nx = tf.Variable(3.0)\nwith tf.GradientTape() as tape:\n    y = x ** 2 + 2 * x + 1\ndy_dx = tape.gradient(y, x)  # 8.0\n\n# カスタム訓練ループ\nwith tf.GradientTape() as tape:\n    predictions = model(x_batch, training=True)\n    loss = loss_fn(y_batch, predictions)\ngrads = tape.gradient(loss, model.trainable_variables)\noptimizer.apply_gradients(zip(grads, model.trainable_variables))",
      "note": "TensorFlowの自動微分メカニズム",
      "doc": "https://www.tensorflow.org/guide/autodiff"
    },
    {
      "term": "テンソル演算",
      "cat": "基礎",
      "code": "import tensorflow as tf\n\n# テンソル作成\na = tf.constant([[1,2],[3,4]], dtype=tf.float32)\nb = tf.ones([2,2])\n\n# 演算\nc = tf.matmul(a, b)     # 行列積\nd = tf.reduce_mean(a)    # 平均\ne = tf.reshape(a, [4])   # 形状変更\nf = tf.concat([a, b], axis=0)  # 結合\n\n# ブロードキャスト\ng = a + tf.constant([10, 20])  # [11,22; 13,24]",
      "note": "多次元配列の基本操作",
      "doc": "https://www.tensorflow.org/guide/tensor"
    },
    {
      "term": "カスタムレイヤー",
      "cat": "基礎",
      "code": "import tensorflow as tf\n\nclass MyDense(tf.keras.layers.Layer):\n    def __init__(self, units):\n        super().__init__()\n        self.units = units\n    \n    def build(self, input_shape):\n        self.w = self.add_weight(\n            shape=(input_shape[-1], self.units),\n            initializer='glorot_uniform',\n            trainable=True\n        )\n        self.b = self.add_weight(\n            shape=(self.units,),\n            initializer='zeros',\n            trainable=True\n        )\n    \n    def call(self, inputs):\n        return tf.matmul(inputs, self.w) + self.b",
      "note": "tf.keras.layers.Layerを継承したカスタムレイヤー",
      "doc": "https://www.tensorflow.org/guide/keras/custom_layers_and_models"
    },
    {
      "term": "カスタム訓練ループ",
      "cat": "基礎",
      "code": "import tensorflow as tf\n\noptimizer = tf.keras.optimizers.Adam()\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n\n@tf.function\ndef train_step(x, y):\n    with tf.GradientTape() as tape:\n        logits = model(x, training=True)\n        loss = loss_fn(y, logits)\n    grads = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n    return loss\n\nfor epoch in range(10):\n    for x_batch, y_batch in dataset:\n        loss = train_step(x_batch, y_batch)",
      "note": "model.fit()を使わない柔軟な訓練実装",
      "doc": "https://www.tensorflow.org/guide/keras/writing_a_training_loop"
    },
    {
      "term": "コールバック",
      "cat": "運用",
      "code": "import tensorflow as tf\n\ncbs = [\n    # EarlyStopping\n    tf.keras.callbacks.EarlyStopping(\n        monitor='val_loss',\n        patience=5\n    ),\n    # Checkpoint\n    tf.keras.callbacks.ModelCheckpoint(\n        'best.keras',\n        save_best_only=True\n    ),\n    # ReduceLROnPlateau\n    tf.keras.callbacks.ReduceLROnPlateau(\n        factor=0.5,\n        patience=3\n    )\n]\nmodel.fit(x, y, callbacks=cbs)",
      "note": "訓練中にフック処理を実行する仕組み",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks"
    },
    {
      "term": "Functional API",
      "cat": "基礎",
      "code": "import tensorflow as tf\nfrom tensorflow.keras import layers\n\n# 多入力・多出力モデル\ninput_a = layers.Input(shape=(32,))\ninput_b = layers.Input(shape=(64,))\n\nx = layers.Dense(128, activation='relu')(input_a)\ny = layers.Dense(128, activation='relu')(input_b)\n\ncombined = layers.Concatenate()([x, y])\noutput_1 = layers.Dense(10, activation='softmax', name='class')(combined)\noutput_2 = layers.Dense(1, name='score')(combined)\n\nmodel = tf.keras.Model(\n    inputs=[input_a, input_b],\n    outputs=[output_1, output_2]\n)",
      "note": "複雑なモデル構造を構築するためのAPI",
      "doc": "https://www.tensorflow.org/guide/keras/functional_api"
    },
    {
      "term": "DenseNet",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\n\nbase = tf.keras.applications \\\n    .DenseNet121(\n        weights='imagenet',\n        include_top=False,\n        input_shape=(224,224,3)\n    )\n# 特徴再利用で高効率\nmodel = tf.keras.Sequential([\n    base,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(10, activation='softmax')\n])",
      "note": "各層が全ての前方層と接続するDense Block構造",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/DenseNet121"
    },
    {
      "term": "Inception",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\n\nbase = tf.keras.applications \\\n    .InceptionV3(\n        weights='imagenet',\n        include_top=False,\n        input_shape=(299,299,3)\n    )\n# 複数サイズフィルタを並列適用\nmodel = tf.keras.Sequential([\n    base,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(10, activation='softmax')\n])",
      "note": "複数サイズのフィルタを並列適用するInception Module",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/InceptionV3"
    },
    {
      "term": "Xception",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\n\nbase = tf.keras.applications.Xception(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(299,299,3)\n)\nmodel = tf.keras.Sequential([\n    base,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(10, activation='softmax')\n])",
      "note": "Depthwise Separable ConvでInceptionを改良",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/Xception"
    },
    {
      "term": "Grad-CAM",
      "cat": "応用",
      "code": "import tensorflow as tf\nimport numpy as np\n\ndef grad_cam(model, image, layer_name, class_idx):\n    grad_model = tf.keras.Model(\n        model.input,\n        [model.get_layer(layer_name).output, model.output]\n    )\n    with tf.GradientTape() as tape:\n        conv_out, preds = grad_model(image[tf.newaxis])\n        loss = preds[0, class_idx]\n    grads = tape.gradient(loss, conv_out)\n    weights = tf.reduce_mean(grads, axis=(1,2))\n    cam = tf.reduce_sum(conv_out[0] * weights, axis=-1)\n    cam = tf.nn.relu(cam)\n    return cam / (tf.reduce_max(cam) + 1e-8)",
      "note": "CNNの判断根拠を可視化するヒートマップ",
      "doc": "https://www.tensorflow.org/tutorials/interpretability/integrated_gradients"
    },
    {
      "term": "Label Smoothing",
      "cat": "正則化",
      "code": "import tensorflow as tf\n\nloss = tf.keras.losses \\\n    .CategoricalCrossentropy(\n        label_smoothing=0.1\n    )\n# [0,1,0] -> [0.03, 0.93, 0.03]",
      "note": "正解ラベルを少しソフトにして過学習を防止",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy"
    },
    {
      "term": "Depthwise畳み込み",
      "cat": "レイヤー",
      "code": "import tensorflow as tf\n\n# Depthwise Convolution\nmodel.add(tf.keras.layers.DepthwiseConv2D(\n    kernel_size=3,\n    padding='same',\n    activation='relu'\n))\n# 続けて Pointwise (1x1)\nmodel.add(tf.keras.layers.Conv2D(64, 1, activation='relu'))",
      "note": "チャネル毎に独立した空間フィルタを適用",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/DepthwiseConv2D"
    },
    {
      "term": "Dilated Convolution",
      "cat": "レイヤー",
      "code": "import tensorflow as tf\n\n# Dilated Conv\nmodel.add(tf.keras.layers.Conv2D(\n    64, 3,\n    dilation_rate=2, # 受容野拡大\n    padding='same'\n))\n# 3x3フィルタで受容野5x5相当",
      "note": "フィルタに隙間を入れて受容野を拡大",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D"
    },
    {
      "term": "グループ正規化",
      "cat": "正則化",
      "code": "import tensorflow as tf\n\nx = tf.keras.layers \\\n    .GroupNormalization(\n        groups=32, axis=-1\n    )(x)\n# バッチサイズ依存なし",
      "note": "チャネルをグループに分けて正規化。バッチサイズに非依存",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/GroupNormalization"
    },
    {
      "term": "DropConnect",
      "cat": "正則化",
      "code": "import tensorflow as tf\n\nclass DropConnect(tf.keras.layers.Layer):\n    def __init__(self, units, rate=0.5):\n        super().__init__()\n        self.units = units\n        self.rate = rate\n    def build(self, input_shape):\n        self.w = self.add_weight(shape=(input_shape[-1], self.units))\n        self.b = self.add_weight(shape=(self.units,))\n    def call(self, x, training=False):\n        if training:\n            mask = tf.random.uniform(tf.shape(self.w)) > self.rate\n            w = self.w * tf.cast(mask, tf.float32)\n        else:\n            w = self.w * (1 - self.rate)\n        return tf.matmul(x, w) + self.b",
      "note": "Dropoutの重み版。重みをランダムに0にする",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers"
    },
    {
      "term": "Cosine Similarity",
      "cat": "評価",
      "code": "import tensorflow as tf\n\n# コサイン類似度損失\nloss = tf.keras.losses.CosineSimilarity()\n\n# 計算\na = tf.constant([1.0, 2.0, 3.0])\nb = tf.constant([4.0, 5.0, 6.0])\nsim = tf.keras.losses.cosine_similarity(a, b)\nprint(sim)  # 高いほど類似",
      "note": "ベクトル間の角度に基づく類似度",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/CosineSimilarity"
    },
    {
      "term": "Triplet Loss",
      "cat": "損失関数",
      "code": "import tensorflow as tf\n\ndef triplet_loss(anchor, pos, neg, margin=1.0):\n    pos_dist = tf.reduce_sum(\n        tf.square(anchor - pos), -1)\n    neg_dist = tf.reduce_sum(\n        tf.square(anchor - neg), -1)\n    loss = tf.maximum(\n        pos_dist - neg_dist + margin, 0.0)\n    return tf.reduce_mean(loss)",
      "note": "アンカー・正例・負例の距離関係を学習する損失",
      "doc": "https://www.tensorflow.org/addons/tutorials/losses_triplet"
    },
    {
      "term": "Focal Loss",
      "cat": "損失関数",
      "code": "import tensorflow as tf\n\ndef focal_loss(y_true, y_pred,\n               gamma=2.0, alpha=0.25):\n    bce = tf.keras.losses \\\n        .binary_crossentropy(y_true, y_pred)\n    p_t = y_true * y_pred \\\n          + (1-y_true) * (1-y_pred)\n    weight = alpha * tf.pow(1-p_t, gamma)\n    return weight * bce",
      "note": "クラス不均衡に対応する重み付き損失関数",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/losses"
    }
  ]
}