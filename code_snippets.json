{
  "snippets": [
    {
      "term": "ReLU",
      "cat": "活性化関数",
      "code": "import tensorflow as tf\n\n# Denseレイヤーで指定\nmodel.add(tf.keras.layers.Dense(\n    64,                # units: 出力ユニット数\n    activation='relu'  # x>0→x, x≤0→0 を適用\n))\n\n# 関数として使用（テンソルに直接適用）\nx = tf.keras.activations.relu(x)",
      "note": "x<0で勾配0。深層学習の標準活性化関数",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/relu"
    },
    {
      "term": "Leaky ReLU",
      "cat": "活性化関数",
      "code": "from tensorflow.keras.layers import LeakyReLU\n\nmodel.add(LeakyReLU(\n    alpha=0.01  # 負の傾き係数（x<0でα*xを出力、0に近いほどReLUに近い）\n))\n\n# alpha=0.1 → 負側の勾配を大きめに残す\nx = LeakyReLU(alpha=0.1)(x)",
      "note": "x<0でも小さな勾配αを持ち、dying neuron問題を緩和",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/LeakyReLU"
    },
    {
      "term": "GELU",
      "cat": "活性化関数",
      "code": "import tensorflow as tf\n\nmodel.add(tf.keras.layers.Dense(\n    64,                # units: 出力ユニット数\n    activation='gelu'  # ガウス誤差線形ユニット（滑らかなReLU）\n))\n\n# 関数として直接適用（BERT/GPT等で標準）\nx = tf.keras.activations.gelu(x)",
      "note": "Transformerで標準的に使用される活性化関数",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/gelu"
    },
    {
      "term": "Sigmoid function",
      "cat": "活性化関数",
      "code": "import tensorflow as tf\n\nmodel.add(tf.keras.layers.Dense(\n    1,                   # units=1: 二値分類なので出力1つ\n    activation='sigmoid' # 出力を(0,1)の確率値に変換\n))\n\n# 関数として使用（ロジットを確率に変換）\nx = tf.keras.activations.sigmoid(x)",
      "note": "出力を(0,1)に写像。二値分類の出力層で使用",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/sigmoid"
    },
    {
      "term": "tanh",
      "cat": "活性化関数",
      "code": "import tensorflow as tf\n\nmodel.add(tf.keras.layers.Dense(\n    64,               # units: 出力ユニット数\n    activation='tanh' # 出力を(-1,1)に写像（零中心で学習が安定）\n))\nx = tf.keras.activations.tanh(x)",
      "note": "出力を(-1,1)に写像。RNNの隠れ状態で使用",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/tanh"
    },
    {
      "term": "ソフトマックス関数",
      "cat": "活性化関数",
      "code": "import tensorflow as tf\n\n# 多クラス分類の出力層\nmodel.add(tf.keras.layers.Dense(\n    10,                  # units=10: クラス数（10クラス分類）\n    activation='softmax' # 出力を確率分布に変換（合計1.0）\n))\n\n# 温度付きSoftmax（蒸留等で使用）\ndef softmax_with_temp(logits, temperature=1.0):\n    # temperature: 高い→分布が平坦、低い→尖鋭化\n    return tf.nn.softmax(logits / temperature)",
      "note": "K次元ベクトルを確率分布に変換。多クラス分類の出力層",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/softmax"
    },
    {
      "term": "Swish",
      "cat": "活性化関数",
      "code": "import tensorflow as tf\n\nmodel.add(tf.keras.layers.Dense(\n    64,                # units: 出力ユニット数\n    activation='swish' # f(x)=x*sigmoid(x) 自己ゲート型、負側も滑らかに通す\n))\n# EfficientNet等で採用、ReLUより性能が良い場合が多い",
      "note": "自己ゲート型活性化関数。EfficientNetで採用",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/activations/swish"
    },
    {
      "term": "Adam",
      "cat": "最適化",
      "code": "import tensorflow as tf\n\noptimizer = tf.keras.optimizers.Adam(\n    learning_rate=0.001, # 学習率（大きい→高速だが不安定、小さい→安定だが遅い）\n    beta_1=0.9,          # 一次モーメント（勾配の移動平均）の減衰率\n    beta_2=0.999,        # 二次モーメント（勾配²の移動平均）の減衰率\n    epsilon=1e-07        # ゼロ除算防止の微小値\n)\nmodel.compile(optimizer=optimizer, loss='mse')",
      "note": "Momentum+RMSPropの統合。最も広く使われる最適化器",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam"
    },
    {
      "term": "AdamW",
      "cat": "最適化",
      "code": "import tensorflow as tf\n\noptimizer = tf.keras.optimizers.AdamW(\n    learning_rate=0.001, # 学習率\n    weight_decay=0.01    # 重み減衰率（L2正則化と異なり学習率と独立）\n)\nmodel.compile(optimizer=optimizer, loss='mse')",
      "note": "重み減衰をL2正則化から分離した改良版Adam",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/AdamW"
    },
    {
      "term": "確率的勾配降下法",
      "cat": "最適化",
      "code": "import tensorflow as tf\n\noptimizer = tf.keras.optimizers.SGD(\n    learning_rate=0.01, # 学習率（SGDは他より大きめに設定することが多い）\n    momentum=0.9,       # 慣性項（過去の勾配を蓄積、0→慣性なし、0.9が一般的）\n    nesterov=True        # Nesterov加速勾配法（先読み勾配で収束を高速化）\n)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy')",
      "note": "基本の勾配降下法。momentum/nesterovオプション付き",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD"
    },
    {
      "term": "学習率スケジューリング",
      "cat": "最適化",
      "code": "import tensorflow as tf\n\n# コサインアニーリング（滑らかに学習率を減衰）\nschedule = tf.keras.optimizers.schedules.CosineDecay(\n    initial_learning_rate=0.01, # 開始時の学習率\n    decay_steps=1000            # 何ステップで最小値に到達するか\n)\noptimizer = tf.keras.optimizers.Adam(learning_rate=schedule)\n\n# ReduceLROnPlateau（指標が停滞したら学習率を下げる）\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss', # 監視する指標\n    factor=0.5,         # 学習率をこの倍率で縮小（0.5→半分に）\n    patience=5          # 改善なしを何epoch許容するか\n)",
      "note": "訓練中に学習率を動的に変更する手法",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules"
    },
    {
      "term": "RMSProp",
      "cat": "最適化",
      "code": "import tensorflow as tf\n\noptimizer = tf.keras.optimizers.RMSprop(\n    learning_rate=0.001, # 学習率\n    rho=0.9              # 勾配²の移動平均の減衰率（大きい→安定、小さい→追従が速い）\n)\nmodel.compile(optimizer=optimizer, loss='mse')",
      "note": "勾配の二乗の移動平均で学習率を適応的に調整",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop"
    },
    {
      "term": "交差エントロピー",
      "cat": "損失関数",
      "code": "import tensorflow as tf\n\n# 二値分類（出力: sigmoid、0か1の2クラス）\nmodel.compile(loss='binary_crossentropy')\n\n# 多クラス分類（ラベルがone-hot形式 [0,1,0,...]）\nmodel.compile(loss='categorical_crossentropy')\n\n# 多クラス分類（ラベルが整数 0,1,2,...）\n# → one-hot変換が不要でメモリ節約\nmodel.compile(loss='sparse_categorical_crossentropy')",
      "note": "分類タスクの標準損失関数",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy"
    },
    {
      "term": "損失関数",
      "cat": "損失関数",
      "code": "import tensorflow as tf\n\n# MSE: 回帰タスクの標準損失（二乗誤差の平均）\nloss = tf.keras.losses.MeanSquaredError()\n\n# MAE: 絶対誤差の平均（外れ値に強い）\nloss = tf.keras.losses.MeanAbsoluteError()\n\n# Huber: MSEとMAEのハイブリッド（外れ値に頼健）\nloss = tf.keras.losses.Huber(\n    delta=1.0  # delta以下→MSE的、delta以上→MAE的に振る舞う\n)\n\n# カスタム損失関数（独自の損失を定義可能）\n@tf.function\ndef custom_loss(y_true, y_pred):\n    return tf.reduce_mean(tf.square(y_true - y_pred))",
      "note": "モデル予測と正解の乖離を定量化",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/losses"
    },
    {
      "term": "Dropout",
      "cat": "正則化",
      "code": "import tensorflow as tf\n\n# Sequentialで追加\nmodel.add(tf.keras.layers.Dropout(\n    0.5  # rate: 無効化するユニットの割合（0.5→50%をランダムにゼロ化）\n))\n\n# Functionalで使用（training=Trueで訓練時のみ適用）\nx = tf.keras.layers.Dropout(0.3)(x, training=True)\n\n# SpatialDropout: CNN向け（チャネル単位でドロップ）\nmodel.add(tf.keras.layers.SpatialDropout2D(\n    0.2  # rate: チャネル全体をドロップする割合\n))",
      "note": "訓練時にランダムにユニットを無効化し過学習を防止",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout"
    },
    {
      "term": "バッチ正規化",
      "cat": "正則化",
      "code": "import tensorflow as tf\n\n# CNNでの典型的使用: Conv → BN → ReLU\nx = tf.keras.layers.Conv2D(\n    64, 3,            # filters=64, kernel_size=3\n    use_bias=False    # BNがバイアスを含むためFalseにしてパラメータ削減\n)(x)\nx = tf.keras.layers.BatchNormalization()(x)  # ミニバッチ内で正規化\nx = tf.keras.layers.ReLU()(x)",
      "note": "ミニバッチ内で正規化し学習を安定化",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization"
    },
    {
      "term": "レイヤー正規化",
      "cat": "正則化",
      "code": "import tensorflow as tf\n\nx = tf.keras.layers.LayerNormalization(\n    epsilon=1e-6  # ゼロ除算防止の微小値（小さいほど精度↑だが不安定になる）\n)(x)\n# バッチサイズに非依存、Transformerで標準的に使用",
      "note": "各サンプルの特徴量次元で正規化。バッチサイズに非依存",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/LayerNormalization"
    },
    {
      "term": "L1正則化",
      "cat": "正則化",
      "code": "import tensorflow as tf\n\n# Dense層にL1正則化（重みを疎にし特徴選択効果）\nmodel.add(tf.keras.layers.Dense(\n    64,\n    kernel_regularizer=tf.keras.regularizers.L1(\n        0.01  # l1: 正則化強度（大きい→重みがより疎に）\n    )\n))\n\n# Elastic Net: L1+L2 の併用\nmodel.add(tf.keras.layers.Dense(\n    64,\n    kernel_regularizer=tf.keras.regularizers.L1L2(\n        l1=0.01,  # L1強度（疎性）\n        l2=0.01   # L2強度（重みの大きさ抑制）\n    )\n))",
      "note": "パラメータを疎にし特徴選択効果がある",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/L1"
    },
    {
      "term": "L2正則化",
      "cat": "正則化",
      "code": "import tensorflow as tf\n\nmodel.add(tf.keras.layers.Dense(\n    64,\n    kernel_regularizer=tf.keras.regularizers.L2(\n        0.01  # l2: 正則化強度（大きい→重みが小さくなりやすい）\n    )\n    # L2は重みを小さく保つ（疎にはしない、L1との違い）\n))",
      "note": "パラメータを小さく保ち過学習を抑制",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/L2"
    },
    {
      "term": "早期終了",
      "cat": "正則化",
      "code": "import tensorflow as tf\n\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',       # 監視する指標（'val_accuracy'等も可）\n    patience=10,              # 改善がない状態を何epoch許容するか\n    restore_best_weights=True # True: 最良時点の重みに復元\n)\nmodel.fit(x, y, epochs=100, callbacks=[early_stop])",
      "note": "検証損失が改善しなくなったら訓練を停止",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping"
    },
    {
      "term": "畳み込み",
      "cat": "レイヤー",
      "code": "import tensorflow as tf\n\n# 2D畳み込み（画像向け）\nmodel.add(tf.keras.layers.Conv2D(\n    filters=32,          # フィルタ数（出力チャネル数）\n    kernel_size=(3,3),   # フィルタサイズ（3x3が標準）\n    strides=1,           # ストライド（フィルタの移動幅、2で解像度半分）\n    padding='same',      # 'same': 出力サイズ維持 / 'valid': パディングなし\n    activation='relu'    # 活性化関数\n))\n\n# 1D畳み込み（系列データ向け）\nmodel.add(tf.keras.layers.Conv1D(\n    64, 3,               # filters=64, kernel_size=3\n    activation='relu'\n))\n\n# 転置畳み込み（アップサンプリング用）\nmodel.add(tf.keras.layers.Conv2DTranspose(\n    32, 3,               # filters=32, kernel_size=3\n    strides=2            # strides=2で解像度2倍に\n))",
      "note": "局所的な特徴を抽出するフィルタ演算",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D"
    },
    {
      "term": "プーリング",
      "cat": "レイヤー",
      "code": "import tensorflow as tf\n\n# MaxPooling: 領域内の最大値を採用（特徴の最大値を保持）\nmodel.add(tf.keras.layers.MaxPooling2D(\n    pool_size=(2,2)  # 2x2領域で解像度を半分に\n))\n\n# AveragePooling: 領域内の平均値（滑らかなダウンサンプリング）\nmodel.add(tf.keras.layers.AveragePooling2D(\n    pool_size=(2,2)\n))\n\n# GlobalAveragePooling: 各チャネルの全空間平均→分類ヘッド前で使用\nmodel.add(tf.keras.layers.GlobalAveragePooling2D())",
      "note": "空間解像度を縮小し位置不変性を獲得",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPooling2D"
    },
    {
      "term": "LSTM",
      "cat": "レイヤー",
      "code": "import tensorflow as tf\n\n# 基本LSTM（最後のタイムステップの出力のみ）\nmodel.add(tf.keras.layers.LSTM(\n    128  # units: 隠れ状態の次元数\n))\n\n# スタックLSTM（複数層を重ねる）\nmodel.add(tf.keras.layers.LSTM(\n    128,\n    return_sequences=True  # True: 全タイムステップの出力を返す（次のRNN層に必要）\n))\nmodel.add(tf.keras.layers.LSTM(64))  # 最後の層は最終出力のみ\n\n# 双方向LSTM（前後両方向から文脈を取得）\nmodel.add(tf.keras.layers.Bidirectional(\n    tf.keras.layers.LSTM(64)\n))",
      "note": "長期依存性を学習できるゲート付きRNN",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM"
    },
    {
      "term": "GRU",
      "cat": "レイヤー",
      "code": "import tensorflow as tf\n\nmodel.add(tf.keras.layers.GRU(\n    128,                  # units: 隠れ状態の次元数\n    return_sequences=True,# True: 全タイムステップの出力を返す\n    dropout=0.2,          # 入力に対するDropout率\n    recurrent_dropout=0.1 # 再帰状態に対するDropout率\n))",
      "note": "LSTMの簡略版。パラメータが少なく高速",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU"
    },
    {
      "term": "Embedding",
      "cat": "レイヤー",
      "code": "import tensorflow as tf\n\n# 単語埋め込み層\nmodel.add(tf.keras.layers.Embedding(\n    input_dim=10000,  # 語彙サイズ（ユニークなトークンの総数）\n    output_dim=128,   # 埋め込みベクトルの次元数（大きい→表現力↑だが計算量↑）\n    input_length=100  # 入力系列の長さ（固定長で入力する場合に指定）\n))",
      "note": "離散トークンを連続ベクトルに変換",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding"
    },
    {
      "term": "Attention",
      "cat": "レイヤー",
      "code": "import tensorflow as tf\n\n# Keras組み込みAttention（Bahdanau型）\nattention = tf.keras.layers.Attention()\noutput = attention([query, value])  # queryとvalueの類似度で重み付け\n\n# MultiHeadAttention (Transformerの中核)\nmha = tf.keras.layers.MultiHeadAttention(\n    num_heads=8,  # ヘッド数（並列に注意を分割、8が標準）\n    key_dim=64    # 各ヘッドのkey/queryの次元数\n)\n# query: 問い合わせ先, value: 値, key: 検索キー\noutput = mha(query, value, key)",
      "note": "入力の重要部分に動的に注目する機構",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention"
    },
    {
      "term": "Dense",
      "cat": "レイヤー",
      "code": "import tensorflow as tf\n\nmodel.add(tf.keras.layers.Dense(\n    units=128,           # 出力ユニット数\n    activation='relu',   # 活性化関数\n    kernel_initializer='he_normal',  # 重み初期化（ReLU系にHeが最適）\n    kernel_regularizer=tf.keras.regularizers.L2(\n        0.01  # L2正則化強度（過学習防止）\n    )\n))",
      "note": "全結合層。input×weightsの行列演算",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense"
    },
    {
      "term": "Flatten",
      "cat": "レイヤー",
      "code": "import tensorflow as tf\n\n# CNN→Dense接続時\nmodel.add(tf.keras.layers.Conv2D(64, 3))\nmodel.add(tf.keras.layers.Flatten())\nmodel.add(tf.keras.layers.Dense(10))",
      "note": "多次元テンソルを1Dに展開",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten"
    },
    {
      "term": "残差接続",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\n\n# Residual Block\ndef residual_block(x, filters):\n    shortcut = x\n    x = tf.keras.layers.Conv2D(filters, 3, padding='same')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.ReLU()(x)\n    x = tf.keras.layers.Conv2D(filters, 3, padding='same')(x)\n    x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.Add()([shortcut, x])\n    x = tf.keras.layers.ReLU()(x)\n    return x",
      "note": "入力をスキップ接続で加算し勾配消失を防止",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Add"
    },
    {
      "term": "ResNet",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\n\n# 学習済みResNet50\nbase = tf.keras.applications.ResNet50(\n    weights='imagenet',       # 'imagenet': 事前学習済み重み / None: ランダム初期化\n    include_top=False,        # False: 分類ヘッドを除外（自分の出力層を付けるため）\n    input_shape=(224,224,3)   # 入力画像サイズ（高さ, 幅, チャネル）\n)\n\n# ファインチューニング\nbase.trainable = False  # まず全層を凍結\nmodel = tf.keras.Sequential([\n    base,\n    tf.keras.layers.GlobalAveragePooling2D(),  # 空間次元を潰す\n    tf.keras.layers.Dense(\n        10, activation='softmax'  # タスクに合わせた出力層\n    )\n])",
      "note": "残差接続を用いた深層CNN",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50"
    },
    {
      "term": "VGG",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\n\nbase = tf.keras.applications.VGG16(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(224,224,3)\n)\nmodel = tf.keras.Sequential([\n    base,\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256, activation='relu'),\n    tf.keras.layers.Dense(10, activation='softmax')\n])",
      "note": "3x3畳み込みを積み重ねたシンプルなCNN",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/VGG16"
    },
    {
      "term": "EfficientNet",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\n\nbase = tf.keras.applications.EfficientNetV2B0(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(224,224,3)\n)\nmodel = tf.keras.Sequential([\n    base,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(10, activation='softmax')\n])",
      "note": "深さ・幅・解像度を複合スケーリング",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/EfficientNetV2B0"
    },
    {
      "term": "U-Net",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\nfrom tensorflow.keras import layers\n\ndef unet(input_shape=(256,256,1)):\n    inputs = layers.Input(input_shape)\n    # Encoder\n    c1 = layers.Conv2D(64,3,padding='same',activation='relu')(inputs)\n    p1 = layers.MaxPooling2D()(c1)\n    c2 = layers.Conv2D(128,3,padding='same',activation='relu')(p1)\n    p2 = layers.MaxPooling2D()(c2)\n    # Bottleneck\n    b = layers.Conv2D(256,3,padding='same',activation='relu')(p2)\n    # Decoder\n    u1 = layers.Conv2DTranspose(128,2,strides=2)(b)\n    u1 = layers.Concatenate()([u1, c2])\n    u1 = layers.Conv2D(128,3,padding='same',activation='relu')(u1)\n    u2 = layers.Conv2DTranspose(64,2,strides=2)(u1)\n    u2 = layers.Concatenate()([u2, c1])\n    u2 = layers.Conv2D(64,3,padding='same',activation='relu')(u2)\n    out = layers.Conv2D(1,1,activation='sigmoid')(u2)\n    return tf.keras.Model(inputs, out)",
      "note": "Encoder-Decoder+スキップ接続のセグメンテーションモデル",
      "doc": "https://www.tensorflow.org/tutorials/images/segmentation"
    },
    {
      "term": "Transformer",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\nfrom tensorflow.keras import layers\n\ndef transformer_block(embed_dim, num_heads, ff_dim, rate=0.1):\n    inputs = layers.Input(shape=(None, embed_dim))\n    attn = layers.MultiHeadAttention(\n        num_heads=num_heads, key_dim=embed_dim\n    )(inputs, inputs)\n    attn = layers.Dropout(rate)(attn)\n    out1 = layers.LayerNormalization()(inputs + attn)\n    ff = layers.Dense(ff_dim, activation='gelu')(out1)\n    ff = layers.Dense(embed_dim)(ff)\n    ff = layers.Dropout(rate)(ff)\n    out2 = layers.LayerNormalization()(out1 + ff)\n    return tf.keras.Model(inputs, out2)",
      "note": "Self-Attentionベースのアーキテクチャ",
      "doc": "https://www.tensorflow.org/text/tutorials/transformer"
    },
    {
      "term": "GAN",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\n\n# Generator\ndef make_generator():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Dense(256, activation='relu', input_shape=(100,)),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dense(512, activation='relu'),\n        tf.keras.layers.Dense(784, activation='sigmoid'),\n        tf.keras.layers.Reshape((28,28,1))\n    ])\n    return model\n\n# Discriminator\ndef make_discriminator():\n    model = tf.keras.Sequential([\n        tf.keras.layers.Flatten(input_shape=(28,28,1)),\n        tf.keras.layers.Dense(512, activation='relu'),\n        tf.keras.layers.Dropout(0.3),\n        tf.keras.layers.Dense(1, activation='sigmoid')\n    ])\n    return model",
      "note": "生成器と判別器の敵対的学習",
      "doc": "https://www.tensorflow.org/tutorials/generative/dcgan"
    },
    {
      "term": "VAE",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\nfrom tensorflow.keras import layers\n\n# Encoder\nlatent_dim = 2\nencoder_inputs = layers.Input(shape=(28,28,1))\nx = layers.Flatten()(encoder_inputs)\nx = layers.Dense(256, activation='relu')(x)\nz_mean = layers.Dense(latent_dim)(x)\nz_log_var = layers.Dense(latent_dim)(x)\n\n# Reparameterization trick\ndef sampling(args):\n    z_mean, z_log_var = args\n    eps = tf.random.normal(shape=tf.shape(z_mean))\n    return z_mean + tf.exp(0.5*z_log_var) * eps",
      "note": "確率的潜在空間を持つ生成モデル",
      "doc": "https://www.tensorflow.org/tutorials/generative/cvae"
    },
    {
      "term": "オートエンコーダ",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\n\n# Encoder\nencoder = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(32, activation='relu')  # bottleneck\n])\n# Decoder\ndecoder = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(784, activation='sigmoid')\n])\n# Autoencoder\ninputs = tf.keras.Input(shape=(784,))\nencoded = encoder(inputs)\ndecoded = decoder(encoded)\nautoencoder = tf.keras.Model(inputs, decoded)\nautoencoder.compile(optimizer='adam', loss='mse')",
      "note": "入力を圧縮・復元する教師なし学習モデル",
      "doc": "https://www.tensorflow.org/tutorials/generative/autoencoder"
    },
    {
      "term": "データ拡張",
      "cat": "前処理",
      "code": "import tensorflow as tf\n\naugmentation = tf.keras.Sequential([\n    tf.keras.layers.RandomFlip('horizontal'),     # 水平方向にランダム反転\n    tf.keras.layers.RandomRotation(0.1),          # ±10%(±36°)の範囲で回転\n    tf.keras.layers.RandomZoom(0.1),              # ±10%の範囲でズーム\n    tf.keras.layers.RandomContrast(0.1),          # ±10%のコントラスト変化\n    tf.keras.layers.RandomTranslation(0.1, 0.1),  # 縦横±10%平行移動\n])\n\n# モデルに組み込み（訓練時のみ適用される）\nmodel = tf.keras.Sequential([\n    augmentation,\n    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n    ...\n])",
      "note": "訓練データを変換して量を増やし汎化性能を向上",
      "doc": "https://www.tensorflow.org/tutorials/images/data_augmentation"
    },
    {
      "term": "RandAugment",
      "cat": "前処理",
      "code": "import tensorflow as tf\n\n# tf.image ベースの実装\ndef randaugment(image, num_ops=2, magnitude=9):\n    augmentations = [\n        lambda img: tf.image.random_brightness(img, 0.2),\n        lambda img: tf.image.random_contrast(img, 0.8, 1.2),\n        lambda img: tf.image.random_saturation(img, 0.8, 1.2),\n        lambda img: tf.image.rot90(img, k=tf.random.uniform([], 0, 4, tf.int32)),\n    ]\n    for _ in range(num_ops):\n        op = augmentations[tf.random.uniform([], 0, len(augmentations), tf.int32)]\n        image = op(image)\n    return image",
      "note": "ランダムにN個の拡張を適用するシンプルな手法",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/image"
    },
    {
      "term": "Mixup",
      "cat": "前処理",
      "code": "import tensorflow as tf\n\ndef mixup(images, labels, alpha=0.2):\n    batch_size = tf.shape(images)[0]\n    lam = tf.random.uniform([batch_size,1,1,1], 0, alpha)\n    indices = tf.random.shuffle(tf.range(batch_size))\n    mixed_images = lam*images + (1-lam)*tf.gather(images, indices)\n    lam_labels = tf.reshape(lam, [batch_size,1])\n    mixed_labels = lam_labels*labels + (1-lam_labels)*tf.gather(labels, indices)\n    return mixed_images, mixed_labels",
      "note": "2つのサンプルを線形補間して正則化効果を得る"
    },
    {
      "term": "転移学習",
      "cat": "学習手法",
      "code": "import tensorflow as tf\n\n# ImageNetで事前学習済みモデル\nbase = tf.keras.applications.MobileNetV2(\n    weights='imagenet',       # 事前学習済み重みを使用\n    include_top=False,        # 分類ヘッドを除外\n    input_shape=(224,224,3)   # 入力画像サイズ\n)\nbase.trainable = False  # まず全層を凍結（特徴抽出層をそのまま使用）\n\nmodel = tf.keras.Sequential([\n    base,\n    tf.keras.layers.GlobalAveragePooling2D(),  # 空間次元を平均化\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dropout(0.3),  # 過学習防止\n    tf.keras.layers.Dense(5, activation='softmax')  # 5クラス分類\n])\n\n# 段階的アンフリーズ（上位層から徐々に解凍）\nbase.trainable = True\nfor layer in base.layers[:-30]:  # 下位30層以外を凍結維持\n    layer.trainable = False",
      "note": "事前学習モデルを新タスクに適応させる手法",
      "doc": "https://www.tensorflow.org/tutorials/images/transfer_learning"
    },
    {
      "term": "ファインチューニング",
      "cat": "学習手法",
      "code": "import tensorflow as tf\n\n# 低学習率でファインチューニング\nmodel.compile(\n    optimizer=tf.keras.optimizers.Adam(\n        learning_rate=1e-5  # 通常より低い学習率（事前学習済み重みを壊さないため）\n    ),\n    loss='sparse_categorical_crossentropy',  # 整数ラベルの多クラス分類\n    metrics=['accuracy']\n)\n\n# 特定の層だけ学習可能に（上位層を微調整）\nfor layer in model.layers[-10:]:\n    layer.trainable = True  # 最後の10層のみ学習対象",
      "note": "事前学習済みモデルの一部をタスク固有データで再学習",
      "doc": "https://www.tensorflow.org/tutorials/images/transfer_learning"
    },
    {
      "term": "知識蒸留",
      "cat": "学習手法",
      "code": "import tensorflow as tf\n\ndef distillation_loss(y_true, y_pred, teacher_pred,\n                      temperature=3.0, alpha=0.5):\n    # temperature: 蒸留温度（高い→ソフトターゲットが滑らかに）\n    # alpha: 蒸留損失とハード損失の混合比率\n    soft_targets = tf.nn.softmax(teacher_pred / temperature)\n    soft_pred = tf.nn.softmax(y_pred / temperature)\n    # 教師のソフト出力とのKLダイバージェンス\n    distill = tf.keras.losses.KLDivergence()(soft_targets, soft_pred)\n    # 通常のハードラベル損失\n    hard = tf.keras.losses.SparseCategoricalCrossentropy(\n        from_logits=True)(y_true, y_pred)\n    # temperature²でスケーリング補正\n    return alpha * distill * temperature**2 + (1-alpha) * hard",
      "note": "大きな教師モデルの知識を小さな生徒モデルに転移",
      "doc": "https://www.tensorflow.org/model_optimization/guide/knowledge_distillation"
    },
    {
      "term": "勾配クリッピング",
      "cat": "学習手法",
      "code": "import tensorflow as tf\n\n# Optimizerで勾配クリッピングを指定\noptimizer = tf.keras.optimizers.Adam(\n    learning_rate=0.001,\n    clipnorm=1.0    # L2ノルムが1.0を超えたらスケーリング\n    # clipvalue=0.5  # 値でクリップ（各要素を[-0.5, 0.5]に制限）\n)",
      "note": "勾配爆発を防止するためにノルムを制限",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam"
    },
    {
      "term": "バッチサイズ",
      "cat": "学習手法",
      "code": "import tensorflow as tf\n\nmodel.fit(\n    x_train, y_train,\n    batch_size=32,        # 1回の更新で使うサンプル数（小→ノイズ多、大→メモリ大）\n    epochs=100,           # 訓練データ全体を何周学習するか\n    validation_split=0.2  # 訓練データの20%を検証用に分割\n)\n\n# tf.data.Datasetで高効率パイプライン\nds = tf.data.Dataset.from_tensor_slices((x, y))\nds = ds.shuffle(1000)        # シャッフルバッファサイズ\nds = ds.batch(64)            # バッチサイズ64\nds = ds.prefetch(tf.data.AUTOTUNE)  # 次のバッチを事前読み込み",
      "note": "1回の更新で使用するサンプル数",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit"
    },
    {
      "term": "Depthwise Separable Conv",
      "cat": "レイヤー",
      "code": "import tensorflow as tf\n\n# Depthwise Separable Convolution\nmodel.add(tf.keras.layers.SeparableConv2D(\n    filters=64, kernel_size=3,\n    padding='same', activation='relu'\n))\n\n# MobileNetで多用される",
      "note": "チャネル毎の空間畳み込み+1x1畳み込みで軽量化",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/SeparableConv2D"
    },
    {
      "term": "MobileNet",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\n\nbase = tf.keras.applications.MobileNetV2(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(224,224,3),\n    alpha=1.0  # モデル幅\n)\n\n# TFLite向け量子化\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\ntflite_model = converter.convert()",
      "note": "Depthwise Separable Convによる軽量モデル",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/MobileNetV2"
    },
    {
      "term": "重み初期化",
      "cat": "学習手法",
      "code": "import tensorflow as tf\n\n# He初期化: ReLU系活性化関数向け（分散を維持）\nmodel.add(tf.keras.layers.Dense(\n    64, activation='relu',\n    kernel_initializer='he_normal'  # 正規分布版He / 'he_uniform'もある\n))\n\n# Xavier/Glorot初期化: sigmoid/tanh系向け\nmodel.add(tf.keras.layers.Dense(\n    64, activation='tanh',\n    kernel_initializer='glorot_uniform'  # Kerasのデフォルト\n    # 'glorot_normal'も選択可\n))",
      "note": "層の重みの初期値を適切に設定し学習を安定化",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/initializers"
    },
    {
      "term": "PCA",
      "cat": "次元削減",
      "code": "import tensorflow as tf\nimport numpy as np\n\n# TensorFlowでPCA\ndef pca_tf(data, n_components):\n    mean = tf.reduce_mean(data, axis=0)\n    centered = data - mean\n    cov = tf.linalg.matmul(centered, centered, transpose_a=True) / tf.cast(tf.shape(data)[0]-1, tf.float32)\n    eigenvalues, eigenvectors = tf.linalg.eigh(cov)\n    # 上位n_components\n    idx = tf.argsort(eigenvalues, direction='DESCENDING')[:n_components]\n    components = tf.gather(eigenvectors, idx, axis=1)\n    return tf.linalg.matmul(centered, components)",
      "note": "分散最大方向に次元削減する主成分分析",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/linalg/eigh"
    },
    {
      "term": "混同行列",
      "cat": "評価",
      "code": "import tensorflow as tf\n\n# 予測と正解から混同行列\ny_true = [0, 1, 2, 0, 1, 2]\ny_pred = [0, 2, 1, 0, 1, 1]\n\ncm = tf.math.confusion_matrix(y_true, y_pred, num_classes=3)\nprint(cm)\n\n# Kerasメトリクス\nmetric = tf.keras.metrics.AUC()\nmetric.update_state(y_true_binary, y_pred_proba)",
      "note": "分類結果をTP/FP/TN/FNで整理した行列",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/math/confusion_matrix"
    },
    {
      "term": "F1スコア",
      "cat": "評価",
      "code": "import tensorflow as tf\n\nclass F1Score(tf.keras.metrics.Metric):\n    def __init__(self, name='f1', **kwargs):\n        super().__init__(name=name, **kwargs)\n        self.precision = tf.keras.metrics.Precision()\n        self.recall = tf.keras.metrics.Recall()\n    def update_state(self, y_true, y_pred, **kw):\n        self.precision.update_state(y_true, y_pred, **kw)\n        self.recall.update_state(y_true, y_pred, **kw)\n    def result(self):\n        p = self.precision.result()\n        r = self.recall.result()\n        return 2 * p * r / (p + r + 1e-7)\n\nmodel.compile(metrics=[F1Score()])",
      "note": "精度と再現率の調和平均",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/metrics"
    },
    {
      "term": "モデルの保存",
      "cat": "運用",
      "code": "import tensorflow as tf\n\n# SavedModel形式（モデル全体を保存）\nmodel.save('my_model')  # ディレクトリに保存\nloaded = tf.keras.models.load_model('my_model')  # 復元\n\n# 重みのみ保存（モデル構造は別途必要）\nmodel.save_weights('weights.h5')\nmodel.load_weights('weights.h5')\n\n# チェックポイント（訓練中の最良モデルを自動保存）\ncp = tf.keras.callbacks.ModelCheckpoint(\n    'best.keras',          # 保存先ファイル名\n    save_best_only=True,   # True: 最良モデルのみ保存\n    monitor='val_accuracy'  # 監視する指標\n)\nmodel.fit(x, y, callbacks=[cp])",
      "note": "学習済みモデルの永続化と復元",
      "doc": "https://www.tensorflow.org/guide/keras/save_and_serialize"
    },
    {
      "term": "TensorBoard",
      "cat": "運用",
      "code": "import tensorflow as tf\n\n# TensorBoardコールバック\ntb = tf.keras.callbacks.TensorBoard(\n    log_dir='./logs',      # ログ保存ディレクトリ\n    histogram_freq=1       # 何epochごとに重みヒストグラムを記録（0=無効）\n)\nmodel.fit(x, y, callbacks=[tb])\n\n# カスタムスカラーを手動で記録\nwriter = tf.summary.create_file_writer('./logs')\nwith writer.as_default():\n    tf.summary.scalar(\n        'custom_metric', value,  # メトリクス名と値\n        step=epoch               # ステップ番号\n    )",
      "note": "学習過程の可視化ツール",
      "doc": "https://www.tensorflow.org/tensorboard"
    },
    {
      "term": "GPU / CUDA",
      "cat": "運用",
      "code": "import tensorflow as tf\n\n# GPU確認\nprint(tf.config.list_physical_devices('GPU'))\n\n# メモリ成長を有効化（必要分だけ確保、OOM防止）\ngpus = tf.config.list_physical_devices('GPU')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(\n        gpu, True  # True: 必要に応じてメモリを段階的に確保\n    )\n\n# 特定GPUを使用\nwith tf.device('/GPU:0'):  # GPU番号を指定\n    model = build_model()",
      "note": "GPUを使用した高速計算",
      "doc": "https://www.tensorflow.org/guide/gpu"
    },
    {
      "term": "混合精度",
      "cat": "運用",
      "code": "import tensorflow as tf\n\n# 混合精度の有効化（グローバル設定）\ntf.keras.mixed_precision.set_global_policy(\n    'mixed_float16'  # 計算はfloat16、勾配累積はfloat32\n)\n\n# モデル構築（自動的にfloat16で計算）\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(\n        10, dtype='float32'  # 出力層はfp32（数値安定性のため）\n    )\n])",
      "note": "float16とfloat32を混合し高速化とメモリ節約",
      "doc": "https://www.tensorflow.org/guide/mixed_precision"
    },
    {
      "term": "量子化",
      "cat": "運用",
      "code": "import tensorflow as tf\n\n# ポストトレーニング量子化（学習後に適用）\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\nconverter.optimizations = [\n    tf.lite.Optimize.DEFAULT  # デフォルト最適化（サイズ縮小+高速化）\n]\ntflite_model = converter.convert()\n\n# INT8完全量子化（更高速、表現データセットが必要）\nconverter.representative_dataset = representative_dataset  # 代表データ\nconverter.target_spec.supported_ops = [\n    tf.lite.OpsSet.TFLITE_BUILTINS_INT8  # INT8演算のみ使用\n]",
      "note": "モデルを低ビット化し推論を高速化・軽量化",
      "doc": "https://www.tensorflow.org/lite/performance/post_training_quantization"
    },
    {
      "term": "tf.data",
      "cat": "運用",
      "code": "import tensorflow as tf\n\n# パイプライン構築\nds = tf.data.Dataset.from_tensor_slices((images, labels))\nds = ds.shuffle(\n    buffer_size=1000  # シャッフルバッファ（大きい→よりランダム、メモリ大）\n)\nds = ds.map(\n    preprocess_fn,\n    num_parallel_calls=tf.data.AUTOTUNE  # 並列処理数を自動最適化\n)\nds = ds.batch(32)  # バッチサイズ\nds = ds.prefetch(\n    tf.data.AUTOTUNE  # 次のバッチをGPU計算中にCPUで準備\n)\n\n# TFRecord読み込み（大規模データ向け）\nds = tf.data.TFRecordDataset('data.tfrecord')\nds = ds.map(parse_fn).batch(32).prefetch(tf.data.AUTOTUNE)",
      "note": "高効率なデータ入力パイプライン",
      "doc": "https://www.tensorflow.org/guide/data"
    },
    {
      "term": "物体検出",
      "cat": "応用",
      "code": "import tensorflow as tf\nimport tensorflow_hub as hub\n\n# TF Hub から学習済みモデル\ndetector = hub.load(\n    'https://tfhub.dev/tensorflow/efficientdet/lite0/detection/1'\n)\n\n# 推論\nresult = detector(image_tensor)\nboxes = result['detection_boxes']\nscores = result['detection_scores']\nclasses = result['detection_classes']",
      "note": "画像内のオブジェクトを検出しバウンディングボックスを出力",
      "doc": "https://www.tensorflow.org/hub/tutorials/object_detection"
    },
    {
      "term": "セマンティックセグメンテーション",
      "cat": "応用",
      "code": "import tensorflow as tf\n\n# DeepLabV3+風\nbase = tf.keras.applications.MobileNetV2(\n    input_shape=(256,256,3), include_top=False\n)\n\n# Decoderでアップサンプリング\nx = base.output\nx = tf.keras.layers.Conv2DTranspose(256, 3, strides=2, padding='same')(x)\nx = tf.keras.layers.Conv2DTranspose(128, 3, strides=2, padding='same')(x)\noutput = tf.keras.layers.Conv2D(21, 1, activation='softmax')(x)\n\nmodel = tf.keras.Model(base.input, output)\nmodel.compile(loss='sparse_categorical_crossentropy')",
      "note": "ピクセル単位でクラスを分類",
      "doc": "https://www.tensorflow.org/tutorials/images/segmentation"
    },
    {
      "term": "Seq2Seq",
      "cat": "応用",
      "code": "import tensorflow as tf\n\n# Encoder\nencoder_inputs = tf.keras.Input(shape=(None,))\nenc_emb = tf.keras.layers.Embedding(src_vocab, 256)(encoder_inputs)\nenc_out, state_h, state_c = tf.keras.layers.LSTM(256, return_state=True)(enc_emb)\n\n# Decoder\ndecoder_inputs = tf.keras.Input(shape=(None,))\ndec_emb = tf.keras.layers.Embedding(tgt_vocab, 256)(decoder_inputs)\ndec_out = tf.keras.layers.LSTM(256, return_sequences=True)(\n    dec_emb, initial_state=[state_h, state_c]\n)\noutput = tf.keras.layers.Dense(tgt_vocab, activation='softmax')(dec_out)",
      "note": "入力系列→出力系列の変換モデル",
      "doc": "https://www.tensorflow.org/text/tutorials/nmt_with_attention"
    },
    {
      "term": "Word2Vec",
      "cat": "応用",
      "code": "import tensorflow as tf\n\n# Skip-gram Word2Vec\nvocab_size = 10000\nembedding_dim = 128\n\ntarget = tf.keras.Input(shape=(1,))\ncontext = tf.keras.Input(shape=(1,))\n\nembedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\ntarget_emb = embedding(target)\ncontext_emb = embedding(context)\n\ndot = tf.keras.layers.Dot(axes=-1)([target_emb, context_emb])\noutput = tf.keras.layers.Flatten()(dot)\noutput = tf.keras.layers.Dense(1, activation='sigmoid')(output)\n\nmodel = tf.keras.Model([target, context], output)",
      "note": "単語をベクトル空間に埋め込むモデル",
      "doc": "https://www.tensorflow.org/tutorials/text/word2vec"
    },
    {
      "term": "勾配テープ",
      "cat": "基礎",
      "code": "import tensorflow as tf\n\n# 自動微分\nx = tf.Variable(3.0)\nwith tf.GradientTape() as tape:\n    y = x ** 2 + 2 * x + 1\ndy_dx = tape.gradient(y, x)  # 8.0\n\n# カスタム訓練ループ\nwith tf.GradientTape() as tape:\n    predictions = model(x_batch, training=True)\n    loss = loss_fn(y_batch, predictions)\ngrads = tape.gradient(loss, model.trainable_variables)\noptimizer.apply_gradients(zip(grads, model.trainable_variables))",
      "note": "TensorFlowの自動微分メカニズム",
      "doc": "https://www.tensorflow.org/guide/autodiff"
    },
    {
      "term": "テンソル演算",
      "cat": "基礎",
      "code": "import tensorflow as tf\n\n# テンソル作成\na = tf.constant([[1,2],[3,4]], dtype=tf.float32)\nb = tf.ones([2,2])\n\n# 演算\nc = tf.matmul(a, b)     # 行列積\nd = tf.reduce_mean(a)    # 平均\ne = tf.reshape(a, [4])   # 形状変更\nf = tf.concat([a, b], axis=0)  # 結合\n\n# ブロードキャスト\ng = a + tf.constant([10, 20])  # [11,22; 13,24]",
      "note": "多次元配列の基本操作",
      "doc": "https://www.tensorflow.org/guide/tensor"
    },
    {
      "term": "カスタムレイヤー",
      "cat": "基礎",
      "code": "import tensorflow as tf\n\nclass MyDense(tf.keras.layers.Layer):\n    def __init__(self, units):\n        super().__init__()\n        self.units = units\n    \n    def build(self, input_shape):\n        self.w = self.add_weight(\n            shape=(input_shape[-1], self.units),\n            initializer='glorot_uniform',\n            trainable=True\n        )\n        self.b = self.add_weight(\n            shape=(self.units,),\n            initializer='zeros',\n            trainable=True\n        )\n    \n    def call(self, inputs):\n        return tf.matmul(inputs, self.w) + self.b",
      "note": "tf.keras.layers.Layerを継承したカスタムレイヤー",
      "doc": "https://www.tensorflow.org/guide/keras/custom_layers_and_models"
    },
    {
      "term": "カスタム訓練ループ",
      "cat": "基礎",
      "code": "import tensorflow as tf\n\noptimizer = tf.keras.optimizers.Adam()\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n\n@tf.function\ndef train_step(x, y):\n    with tf.GradientTape() as tape:\n        logits = model(x, training=True)\n        loss = loss_fn(y, logits)\n    grads = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n    return loss\n\nfor epoch in range(10):\n    for x_batch, y_batch in dataset:\n        loss = train_step(x_batch, y_batch)",
      "note": "model.fit()を使わない柔軟な訓練実装",
      "doc": "https://www.tensorflow.org/guide/keras/writing_a_training_loop"
    },
    {
      "term": "コールバック",
      "cat": "運用",
      "code": "import tensorflow as tf\n\ncallbacks = [\n    tf.keras.callbacks.EarlyStopping(\n        monitor='val_loss',  # 監視指標\n        patience=5           # 5epoch改善なしで停止\n    ),\n    tf.keras.callbacks.ModelCheckpoint(\n        'best.keras',        # 保存先\n        save_best_only=True  # 最良モデルのみ保存\n    ),\n    tf.keras.callbacks.ReduceLROnPlateau(\n        factor=0.5,          # 学習率を半分に\n        patience=3           # 3epoch改善なしで発動\n    ),\n    tf.keras.callbacks.TensorBoard(\n        log_dir='./logs'     # ログ保存先\n    ),\n    tf.keras.callbacks.CSVLogger(\n        'training.csv'       # 訓練ログをCSVに出力\n    ),\n]\n\nmodel.fit(x, y, epochs=100, callbacks=callbacks)",
      "note": "訓練中にフック処理を実行する仕組み",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/callbacks"
    },
    {
      "term": "Functional API",
      "cat": "基礎",
      "code": "import tensorflow as tf\nfrom tensorflow.keras import layers\n\n# 多入力・多出力モデル\ninput_a = layers.Input(shape=(32,))\ninput_b = layers.Input(shape=(64,))\n\nx = layers.Dense(128, activation='relu')(input_a)\ny = layers.Dense(128, activation='relu')(input_b)\n\ncombined = layers.Concatenate()([x, y])\noutput_1 = layers.Dense(10, activation='softmax', name='class')(combined)\noutput_2 = layers.Dense(1, name='score')(combined)\n\nmodel = tf.keras.Model(\n    inputs=[input_a, input_b],\n    outputs=[output_1, output_2]\n)",
      "note": "複雑なモデル構造を構築するためのAPI",
      "doc": "https://www.tensorflow.org/guide/keras/functional_api"
    },
    {
      "term": "DenseNet",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\n\nbase = tf.keras.applications.DenseNet121(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(224,224,3)\n)\nmodel = tf.keras.Sequential([\n    base,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(10, activation='softmax')\n])",
      "note": "各層が全ての前方層と接続するDense Block構造",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/DenseNet121"
    },
    {
      "term": "Inception",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\n\nbase = tf.keras.applications.InceptionV3(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(299,299,3)\n)\nmodel = tf.keras.Sequential([\n    base,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(10, activation='softmax')\n])",
      "note": "複数サイズのフィルタを並列適用するInception Module",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/InceptionV3"
    },
    {
      "term": "Xception",
      "cat": "モデル構造",
      "code": "import tensorflow as tf\n\nbase = tf.keras.applications.Xception(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(299,299,3)\n)\nmodel = tf.keras.Sequential([\n    base,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(10, activation='softmax')\n])",
      "note": "Depthwise Separable ConvでInceptionを改良",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/applications/Xception"
    },
    {
      "term": "Grad-CAM",
      "cat": "応用",
      "code": "import tensorflow as tf\nimport numpy as np\n\ndef grad_cam(model, image, layer_name, class_idx):\n    grad_model = tf.keras.Model(\n        model.input,\n        [model.get_layer(layer_name).output, model.output]\n    )\n    with tf.GradientTape() as tape:\n        conv_out, preds = grad_model(image[tf.newaxis])\n        loss = preds[0, class_idx]\n    grads = tape.gradient(loss, conv_out)\n    weights = tf.reduce_mean(grads, axis=(1,2))\n    cam = tf.reduce_sum(conv_out[0] * weights, axis=-1)\n    cam = tf.nn.relu(cam)\n    return cam / (tf.reduce_max(cam) + 1e-8)",
      "note": "CNNの判断根拠を可視化するヒートマップ",
      "doc": "https://www.tensorflow.org/tutorials/interpretability/integrated_gradients"
    },
    {
      "term": "Label Smoothing",
      "cat": "正則化",
      "code": "import tensorflow as tf\n\n# Label Smoothing付き交差エントロピー\nloss = tf.keras.losses.CategoricalCrossentropy(\n    label_smoothing=0.1  # 平滑化係数（0.1→正解を0.925、他を0.025に）\n)\n# 効果: one-hot [0,0,1,0] → [0.025, 0.025, 0.925, 0.025]\n# モデルの過信を防ぎ汎化性能を向上",
      "note": "正解ラベルを少しソフトにして過学習を防止",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy"
    },
    {
      "term": "Depthwise畳み込み",
      "cat": "レイヤー",
      "code": "import tensorflow as tf\n\n# Depthwise Convolution\nmodel.add(tf.keras.layers.DepthwiseConv2D(\n    kernel_size=3,\n    padding='same',\n    activation='relu'\n))\n# 続けて Pointwise (1x1)\nmodel.add(tf.keras.layers.Conv2D(64, 1, activation='relu'))",
      "note": "チャネル毎に独立した空間フィルタを適用",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/DepthwiseConv2D"
    },
    {
      "term": "Dilated Convolution",
      "cat": "レイヤー",
      "code": "import tensorflow as tf\n\n# 膨張畳み込み（フィルタに隋間を入れて受容野を拡大）\nmodel.add(tf.keras.layers.Conv2D(\n    64, 3,\n    dilation_rate=2,      # 膨張率（2→フィルタ間ど1ピクセル空ける）\n    padding='same',       # 出力サイズ維持\n    activation='relu'\n))\n# dilation_rate=2 → 3x3フィルタで受容野5x5相当（パラメータ増加なし）",
      "note": "フィルタに隙間を入れて受容野を拡大",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D"
    },
    {
      "term": "グループ正規化",
      "cat": "正則化",
      "code": "import tensorflow as tf\n\n# GroupNormalization\nx = tf.keras.layers.GroupNormalization(\n    groups=32,  # チャネルを何グループに分けるか\n    axis=-1     # 正規化する軸（-1=最後の軸=チャネル）\n)(x)\n# groups=1 → LayerNormと等価\n# groups=C(チャネル数) → InstanceNormと等価",
      "note": "チャネルをグループに分けて正規化。バッチサイズに非依存",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers/GroupNormalization"
    },
    {
      "term": "DropConnect",
      "cat": "正則化",
      "code": "import tensorflow as tf\n\nclass DropConnect(tf.keras.layers.Layer):\n    def __init__(self, units, rate=0.5):\n        super().__init__()\n        self.units = units\n        self.rate = rate\n    def build(self, input_shape):\n        self.w = self.add_weight(shape=(input_shape[-1], self.units))\n        self.b = self.add_weight(shape=(self.units,))\n    def call(self, x, training=False):\n        if training:\n            mask = tf.random.uniform(tf.shape(self.w)) > self.rate\n            w = self.w * tf.cast(mask, tf.float32)\n        else:\n            w = self.w * (1 - self.rate)\n        return tf.matmul(x, w) + self.b",
      "note": "Dropoutの重み版。重みをランダムに0にする",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/layers"
    },
    {
      "term": "Cosine Similarity",
      "cat": "評価",
      "code": "import tensorflow as tf\n\n# コサイン類似度損失\nloss = tf.keras.losses.CosineSimilarity()\n\n# 計算\na = tf.constant([1.0, 2.0, 3.0])\nb = tf.constant([4.0, 5.0, 6.0])\nsim = tf.keras.losses.cosine_similarity(a, b)\nprint(sim)  # 高いほど類似",
      "note": "ベクトル間の角度に基づく類似度",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/losses/CosineSimilarity"
    },
    {
      "term": "Triplet Loss",
      "cat": "損失関数",
      "code": "import tensorflow as tf\n\ndef triplet_loss(anchor, positive, negative, margin=1.0):\n    # anchor: 基準サンプル\n    # positive: anchorと同じクラスのサンプル\n    # negative: anchorと異なるクラスのサンプル\n    # margin: 正例と負例の距離差の最小マージン\n    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n    # 正例より負例がmargin以上遠くなるよう学習\n    loss = tf.maximum(pos_dist - neg_dist + margin, 0.0)\n    return tf.reduce_mean(loss)",
      "note": "アンカー・正例・負例の距離関係を学習する損失",
      "doc": "https://www.tensorflow.org/addons/tutorials/losses_triplet"
    },
    {
      "term": "Focal Loss",
      "cat": "損失関数",
      "code": "import tensorflow as tf\n\ndef focal_loss(y_true, y_pred, gamma=2.0, alpha=0.25):\n    # gamma: 簡単な例の重みを下げる係数（大きい→難しい例に集中）\n    # alpha: クラスバランスの重み係数（少数クラスに大きい値）\n    bce = tf.keras.losses.binary_crossentropy(y_true, y_pred)\n    p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n    focal_weight = alpha * tf.pow(1 - p_t, gamma)  # 確信度が低いほど重み↑\n    return focal_weight * bce",
      "note": "クラス不均衡に対応する重み付き損失関数",
      "doc": "https://www.tensorflow.org/api_docs/python/tf/keras/losses"
    }
  ]
}